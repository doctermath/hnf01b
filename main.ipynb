{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import requests\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing, Holt, ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 16:50:08 - INFO - ========================================\n",
      "2025-01-23 16:50:08 - INFO - BEGIN PYTHON FORECAST PROGRAM FOR SPAREPARTS\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Set Display Width Longer\n",
    "pd.options.display.max_colwidth = 200  # 100 for long width\n",
    "\n",
    "# create folder logs/forecast.log if not exist\n",
    "if not os.path.exists(\"logs\"):\n",
    "    os.makedirs(\"logs\")\n",
    "\n",
    "# Set Logging\n",
    "logging.basicConfig(\n",
    "    format=\"{asctime} - {levelname} - {message}\",\n",
    "    style=\"{\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[logging.FileHandler(\"logs/forecast.log\"), logging.StreamHandler()],\n",
    ")\n",
    "logging.info(\"=\"*40)\n",
    "logging.info(\"BEGIN PYTHON FORECAST PROGRAM FOR SPAREPARTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 16:50:08 - INFO - BEGIN Retrieving API\n",
      "2025-01-23 16:50:08 - INFO - API Data From Start Date: 2023-09-01 to End Date: 2024-12-01\n",
      "2025-01-23 16:50:12 - INFO - Attempt 1: API request failed - HTTPConnectionPool(host='localhost', port=1978): Max retries exceeded with url: /main/web/gdmdcall?start-date=2023-09-01&end-date=2024-12-01&exclude-older=2023-09-01&branch=&agency=&partno= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000212B59EB3D0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "2025-01-23 16:50:19 - INFO - Attempt 2: API request failed - HTTPConnectionPool(host='localhost', port=1978): Max retries exceeded with url: /main/web/gdmdcall?start-date=2023-09-01&end-date=2024-12-01&exclude-older=2023-09-01&branch=&agency=&partno= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000212B59E8130>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "2025-01-23 16:50:27 - INFO - Attempt 3: API request failed - HTTPConnectionPool(host='localhost', port=1978): Max retries exceeded with url: /main/web/gdmdcall?start-date=2023-09-01&end-date=2024-12-01&exclude-older=2023-09-01&branch=&agency=&partno= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021292EBFFD0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "2025-01-23 16:50:39 - INFO - Attempt 4: API request failed - HTTPConnectionPool(host='localhost', port=1978): Max retries exceeded with url: /main/web/gdmdcall?start-date=2023-09-01&end-date=2024-12-01&exclude-older=2023-09-01&branch=&agency=&partno= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021292EBE350>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "2025-01-23 16:50:59 - INFO - Attempt 5: API request failed - HTTPConnectionPool(host='localhost', port=1978): Max retries exceeded with url: /main/web/gdmdcall?start-date=2023-09-01&end-date=2024-12-01&exclude-older=2023-09-01&branch=&agency=&partno= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000212B59EB0A0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n",
      "2025-01-23 16:51:35 - INFO - Attempt 6: API request failed - HTTPConnectionPool(host='localhost', port=1978): Max retries exceeded with url: /main/web/gdmdcall?start-date=2023-09-01&end-date=2024-12-01&exclude-older=2023-09-01&branch=&agency=&partno= (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000212B59EB5B0>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))\n"
     ]
    }
   ],
   "source": [
    "# Retrive data from API\n",
    "logging.info('BEGIN Retrieving API')\n",
    "\n",
    "max_retries=8\n",
    "delay=2\n",
    "\n",
    "# Initialize Start and End Date\n",
    "start_date = (datetime.today().replace(day=1) - relativedelta(months=16)).strftime(\"%Y-%m-%d\") \n",
    "end_date = (datetime.today().replace(day=1) - relativedelta(months=1)).strftime(\"%Y-%m-%d\")  \n",
    "\n",
    "logging.info(f\"API Data From Start Date: {start_date} to End Date: {end_date}\")\n",
    "\n",
    "params = {\n",
    "    \"start-date\": start_date,\n",
    "    \"end-date\": end_date,\n",
    "    \"exclude-older\": start_date,\n",
    "    \"branch\": \"\",\n",
    "    \"agency\": \"\",\n",
    "    \"partno\": \"\"\n",
    "}\n",
    "\n",
    "url = \"http://localhost:8080/main/web/gdmdcall\"\n",
    "    \n",
    "for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        if 'data' in data and 'data-count' in data:\n",
    "            logging.info(str(data['month-count']) + \" Month Data Retrived\")\n",
    "            logging.info(str(data['data-count']) + \" Data retrived from API\")\n",
    "            df = pd.DataFrame(data['data'])\n",
    "            break\n",
    "        else:\n",
    "            logging.info(\"Error: Unexpected API response format\")\n",
    "            break\n",
    "    except requests.RequestException as e:\n",
    "        logging.info(f\"Attempt {attempt}: API request failed - {e}\")\n",
    "        if attempt < max_retries:\n",
    "            time.sleep(delay * (2 ** (attempt - 1)))  # Exponential backoff\n",
    "        else:\n",
    "            logging.info(\"Max retries reached. Exiting.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "# display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:43 - INFO - BEGIN Constructing All Branch Data and Combine It to DF\n",
      "2025-01-22 11:17:43 - INFO - All Branch Data Constructed And Merged With DF With Total Data 20\n"
     ]
    }
   ],
   "source": [
    "# Contruct All Branch Data and Concat It To DF\n",
    "logging.info(\"BEGIN Constructing All Branch Data and Combine It to DF\")\n",
    "\n",
    "df_all = df.groupby([\"agency\", \"partno\"], as_index=False)[\"d\"].apply(\n",
    "    lambda x: np.sum(np.array(x.tolist()), axis=0).tolist()\n",
    ")\n",
    "df_all.insert(0, \"branch\", \"ALL\")\n",
    "df = pd.concat([df, df_all], ignore_index=True)\n",
    "\n",
    "logging.info(\n",
    "    f\"All Branch Data Constructed And Merged With DF With Total Data {len(df)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:43 - INFO - BEGIN Forcast Calculation\n"
     ]
    }
   ],
   "source": [
    "# Calculate Forecast\n",
    "logging.info(\"BEGIN Forecast Calculation\")\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:43 - INFO - BEGIN Mean, Std, UB Calculation, and Construct Clipping Data\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Mean, Std, UB Calculation, and Construct Clipping Data\")\n",
    "\n",
    "# Get mean and standard deviation of 12 periods before the last one\n",
    "df['mean_12'] = df['d'].apply(lambda x: np.mean(x[-13:-1]))  # Use 12 periods before the last one\n",
    "df['std_12'] = df['d'].apply(lambda x: np.std(x[-13:-1]))    # Use 12 periods before the last one\n",
    "\n",
    "# Get upper bound from mean and std\n",
    "df['ub'] = df['mean_12'] + 1.5 * df['std_12']\n",
    "\n",
    "# Limit the original df to upper bound (using the 12 periods before the last one)\n",
    "df['clipped_d'] = df.apply(lambda row: np.clip(row['d'][-13:-1], 0, row['ub']).tolist(), axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "# display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:43 - INFO - BEGIN Simple Moving Average Calculation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Simple Moving Average Calculation\")\n",
    "\n",
    "# Calculate Simple Moving Average\n",
    "df['ma'] = df['clipped_d'].apply(lambda x: pd.Series(x).rolling(window=len(x), min_periods=1).mean().tolist())\n",
    "df['ma_result'] = df['ma'].apply(lambda x: x[-1:])\n",
    "\n",
    "# Display the updated DataFrame\n",
    "# display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:43 - INFO - BEGIN Weighted Moving Average Calculation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Weighted Moving Average Calculation\")\n",
    "\n",
    "df['wma_clipped_d'] = df.apply(lambda row: np.clip(row['d'][-16:-1], 0, row['ub']).tolist(), axis=1)\n",
    "\n",
    "def wma_forecast_with_weights(df, weights):\n",
    "    wma_values = [None] * 3\n",
    "    for i in range(3, len(df)):\n",
    "        forecast = np.sum(np.array(df[i-3:i]) * weights) / sum(weights)\n",
    "        wma_values.append(forecast)\n",
    "    return wma_values\n",
    "\n",
    "def generate_weights(step=0.05):\n",
    "    weights = []\n",
    "    for w1 in np.arange(0.01, 1, step):\n",
    "        for w2 in np.arange(w1 + 0.01, 1 - w1, step):\n",
    "            w3 = 1 - w1 - w2\n",
    "            if w3 > w2 > w1 > 0 and abs(w1 + w2 + w3 - 1) < 1e-6:\n",
    "                weights.append((w1, w2, w3))\n",
    "    return weights\n",
    "\n",
    "best_weights_list = []\n",
    "best_maes = []\n",
    "\n",
    "for row in df['wma_clipped_d']:\n",
    "    best_mae = float('inf')\n",
    "    best_weights = None\n",
    "    for weights in generate_weights(step=0.05):\n",
    "        wma_values = wma_forecast_with_weights(row, weights)\n",
    "        mae = mean_absolute_error(row[-12:], wma_values[-12:])\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_weights = weights\n",
    "    best_weights_list.append(best_weights)\n",
    "    best_maes.append(best_mae)\n",
    "\n",
    "df['best_weights'] = best_weights_list\n",
    "df['best_mae'] = best_maes\n",
    "\n",
    "df['wma'], df['wma_result'] = zip(*df.apply(lambda row: (\n",
    "    wma_forecast_with_weights(row['wma_clipped_d'], row['best_weights'])[3:][-12:],\n",
    "    wma_forecast_with_weights(row['wma_clipped_d'], row['best_weights'])[-1:]\n",
    "), axis=1))\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:44 - INFO - BEGIN Exponential Weighted Moving Average Calculation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Exponential Weighted Moving Average Calculation\")\n",
    "\n",
    "# Calculate Exponential Weighted Moving Average (EWMA)\n",
    "alpha_ewma = 0.4\n",
    "\n",
    "def ewma(list, alpha = alpha_ewma):\n",
    "    df = pd.DataFrame(list)\n",
    "    df['ewma'] = df.ewm(alpha=alpha_ewma, adjust=False).mean()\n",
    "    return df['ewma'].tolist()\n",
    "\n",
    "def ewma_forecast(list, alpha):\n",
    "    ewma_values = ewma(list, alpha)\n",
    "    if len(ewma_values) > 0:\n",
    "        # Prediction for the next period\n",
    "        next_forecast = (1 - alpha) * ewma_values[-1]\n",
    "    else:\n",
    "        next_forecast = None\n",
    "    return ewma_values, next_forecast\n",
    "\n",
    "df['ewma'], df['ewma_result'] = zip(*df['clipped_d'].apply(lambda x: ewma_forecast(x, alpha_ewma)))\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:44 - INFO - BEGIN Linear Reggression Calculation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Linear Reggression Calculation\")\n",
    "\n",
    "#LINEAR REGRESSION\n",
    "#  Calculate Linear Regression\n",
    "def lr(x):\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = x\n",
    "    df['x'] = range(1, len(df) + 1)\n",
    "    model =  LinearRegression()\n",
    "    model.fit(df[['x']], df['y'])\n",
    "    df.loc[len(df), 'x'] = len(df) + 1\n",
    "    return model.predict(df[['x']])\n",
    "\n",
    "df['lr'] = df['clipped_d'].apply(lambda x: lr(x))\n",
    "df['lr_result'] = df['lr'].apply(lambda x: x[-1:])\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:44 - INFO - BEGIN Polynomial Reggression Calculation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Polynomial Reggression Calculation\")\n",
    "\n",
    "#POLYNOMIAL 2ND AND 3RD\n",
    "# Calculate Polynomial Regression\n",
    "def pr(x, pr_degree):\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = x\n",
    "    df['x'] = range(1, len(df) + 1)\n",
    "\n",
    "    X = df[['x']]  # Independent variable (reshape to 2D array)\n",
    "    y = df['y']    # Dependent variable\n",
    "\n",
    "    poly = PolynomialFeatures(degree=pr_degree)  # Create polynomial features\n",
    "    X_poly = poly.fit_transform(X)  # Transform input features\n",
    "    poly_model = LinearRegression()  # Initialize linear regression model\n",
    "    poly_model.fit(X_poly, y)  # Fit polynomial model\n",
    "\n",
    "    df.loc[len(df), 'x'] = len(df) + 1\n",
    "    X_all_poly = poly.transform(df[['x']])\n",
    "    return poly_model.predict(X_all_poly)  \n",
    "\n",
    "df['pr2'] = df['clipped_d'].apply(lambda x: pr(x, 2))\n",
    "df['pr2_result'] = df['pr2'].apply(lambda x: x[-1:])\n",
    "df['pr3'] = df['clipped_d'].apply(lambda x: pr(x, 3))\n",
    "df['pr3_result'] = df['pr3'].apply(lambda x: x[-1:])\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:44 - INFO - BEGIN Simple Exponential Smoothing Calculation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Simple Exponential Smoothing Calculation\")\n",
    "\n",
    "alpha_ses = 0.65  # ubah nilai alpha (semakin besar semakin berat ke data terbaru)\n",
    "\n",
    "#SES\n",
    "def ses(x, alpha = alpha_ses):\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = x\n",
    "    df['x'] = range(1, len(df) + 1)\n",
    "    df.loc[len(df), 'x'] = len(df) + 1\n",
    "\n",
    "    new_data = SimpleExpSmoothing(df['y']).fit(smoothing_level=alpha, optimized=False).fittedvalues\n",
    "    return new_data.tolist()\n",
    "\n",
    "df['ses'] = df['clipped_d'].apply(lambda x: ses(x, alpha_ses))\n",
    "df['ses_result'] = df['ses'].apply(lambda x: x[-1:])\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:44 - INFO - BEGIN Double Exponential Smoothing Calculation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Double Exponential Smoothing Calculation\")\n",
    "\n",
    "beta_des = 0.45\n",
    "\n",
    "#DES\n",
    "def des(x, alpha = alpha_ses, beta = beta_des):\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = x\n",
    "    df['x'] = range(1, len(df) + 1)\n",
    "    df.loc[len(df), 'x'] = len(df) + 1\n",
    "\n",
    "    new_data = ExponentialSmoothing(df['y'], trend='add', seasonal=None).fit(smoothing_level=alpha, smoothing_trend=beta, optimized=False).fittedvalues\n",
    "    return new_data.tolist()\n",
    "\n",
    "df['des'] = df['clipped_d'].apply(lambda x: des(x,alpha_ses, beta_des))\n",
    "df['des_result'] = df['des'].apply(lambda x: x[-1:])\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:44 - INFO - BEGIN Metric Calculation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Metric Calculation\")\n",
    "\n",
    "# Calculate metrics for each model\n",
    "def metric(x):\n",
    "    period_length = len(x['clipped_d'])\n",
    "    df = pd.DataFrame()\n",
    "    df['period'] = range(1, period_length + 1)\n",
    "    df['qty'] = x['clipped_d'][:period_length]  # Ground truth values\n",
    "    df['ma'] = x['ma'][:period_length]\n",
    "    df['wma'] = x['wma'][:period_length]\n",
    "    df['ewma'] = x['ewma'][:period_length]\n",
    "    df['lr'] = x['lr'][:period_length]\n",
    "    df['pr2'] = x['pr2'][:period_length]\n",
    "    df['pr3'] = x['pr3'][:period_length]\n",
    "    df['ses'] = x['ses'][:period_length]\n",
    "    df['des'] = x['des'][:period_length]\n",
    "\n",
    "    # Calculate metrics for each model\n",
    "    result = []\n",
    "    for model in df.columns[2:]:  # Loop through model columns (ma, ewma, etc.)\n",
    "        rmse = np.sqrt(mean_squared_error(df['qty'], df[model]))  # Calculate RMSE\n",
    "        r2 = r2_score(df['qty'], df[model])  # Calculate RÂ²\n",
    "        mae = mean_absolute_error(df['qty'], df[model])  # Calculate MAE\n",
    "        result.append({'model': model, 'RMSE': rmse, 'MAE': mae, 'R2': r2})\n",
    "    \n",
    "    # Convert result to a DataFrame\n",
    "    metrics_df = pd.DataFrame(result)\n",
    "    \n",
    "    # Select the best model (e.g., based on RMSE)\n",
    "    best_model_row = metrics_df.loc[metrics_df['MAE'].idxmin()]  # Row with the lowest RMSE\n",
    "    best_model = best_model_row['model']\n",
    "    \n",
    "    # Add the best model and metrics to the result\n",
    "    return {'best_model': best_model, 'metrics': metrics_df.to_dict(orient='records')}\n",
    "\n",
    "# Apply the metric function\n",
    "df['metric'] = df.apply(lambda x: metric(x), axis=1)\n",
    "\n",
    "# Extract the best model and metrics for each row\n",
    "df['best_model'] = df['metric'].apply(lambda x: x['best_model'])\n",
    "df['metrics'] = df['metric'].apply(lambda x: x['metrics'])\n",
    "\n",
    "# Display the DataFrame\n",
    "# display(df[['wma']])\n",
    "# display(df[['best_model', 'metrics']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:44 - INFO - BEGIN Data Selection Calculation\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"BEGIN Data Selection Calculation\")\n",
    "\n",
    "# Select the best model for each row\n",
    "df['mean_12_FD'] = df['d'].apply(lambda x: np.mean(x[-12:]))\n",
    "df['std_12_FD'] = df['d'].apply(lambda x: np.std(x[-12:]))\n",
    "\n",
    "df['ub_FD'] = df['mean_12_FD'] + 1.5 * df['std_12_FD']\n",
    "\n",
    "df['clipped_d_FD'] = df.apply(lambda row: np.clip(row['d'][-12:], 0, row['ub_FD']).tolist(), axis=1)\n",
    "def apply_best_model_forecast(row):\n",
    "    best_model = row['best_model']\n",
    "    \n",
    "    data = row['d'][-15:] if best_model == 'wma' else row['d'][-12:]\n",
    "    \n",
    "    ub = row['ub_FD']\n",
    "    clipped_data = np.clip(data, 0, ub).tolist()\n",
    "    # print(f\"Clipped data for model {best_model}: {clipped_data}\")\n",
    "    \n",
    "    if best_model == 'ma':\n",
    "        ma_values = pd.Series(clipped_data).rolling(window=len(clipped_data), min_periods=1).mean().tolist()\n",
    "        forecast = ma_values[-1]\n",
    "        # print('ma')\n",
    "    elif best_model == 'ewma':\n",
    "        alpha = 0.4\n",
    "        weights = np.array([(1 - alpha) ** i for i in range(len(clipped_data))][::-1])\n",
    "        forecast = np.sum(weights * clipped_data) / np.sum(weights)\n",
    "        # print('ewma')\n",
    "    elif best_model == 'wma':\n",
    "        weights = [0.2, 0.3, 0.5]\n",
    "        if len(clipped_data) >= len(weights):\n",
    "            forecast = np.sum(np.array(clipped_data[-3:]) * weights)\n",
    "        else:\n",
    "            forecast = np.nan\n",
    "        # print('wma')\n",
    "    elif best_model == 'lr':\n",
    "        X = np.arange(len(clipped_data)).reshape(-1, 1)\n",
    "        y = np.array(clipped_data)\n",
    "        coef = np.polyfit(X.flatten(), y, 1)\n",
    "        forecast = coef[0] * len(clipped_data) + coef[1]\n",
    "        # print('lr')\n",
    "    elif best_model == 'pr2':\n",
    "        X = np.arange(len(clipped_data)).reshape(-1, 1)\n",
    "        y = np.array(clipped_data)\n",
    "        coef = np.polyfit(X.flatten(), y, 2)\n",
    "        forecast = coef[0] * (len(clipped_data) ** 2) + coef[1] * len(clipped_data) + coef[2]\n",
    "        # print('pr2')\n",
    "    elif best_model == 'pr3':\n",
    "        X = np.arange(len(clipped_data)).reshape(-1, 1)\n",
    "        y = np.array(clipped_data)\n",
    "        coef = np.polyfit(X.flatten(), y, 3)\n",
    "        forecast = (\n",
    "            coef[0] * (len(clipped_data) ** 3)\n",
    "            + coef[1] * (len(clipped_data) ** 2)\n",
    "            + coef[2] * len(clipped_data)\n",
    "            + coef[3]\n",
    "        )\n",
    "    elif best_model == 'ses':\n",
    "        model = SimpleExpSmoothing(clipped_data).fit(smoothing_level=0.65, optimized=False)\n",
    "        forecast = model.forecast(1)[0]\n",
    "        # print('ses')\n",
    "    elif best_model == 'des':\n",
    "        model = Holt(clipped_data).fit(smoothing_level=0.65, smoothing_slope=0.45, optimized=False)\n",
    "        forecast = model.forecast(1)[0]\n",
    "        # print('des')\n",
    "    else:\n",
    "        forecast = np.nan\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "df['FD_forecast'] = df.apply(apply_best_model_forecast, axis=1)\n",
    "\n",
    "df['FD_final'] = df['FD_forecast'].apply(np.ceil)\n",
    "\n",
    "# display(df[['best_model', 'FD_forecast', 'FD_final']])\n",
    "# display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:45 - INFO - Forcast Calculation Completed\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Forecast Calculation Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:45 - INFO - Begin Creating Excel For DataFrame\n",
      "2025-01-22 11:17:45 - INFO - Excel File Created: output/forecast_2025-01-22.xlsx, Size: 0.01 MB\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Begin Creating Excel For DataFrame\")\n",
    "\n",
    "# if output folder not exist, create it\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "\n",
    "# Create Excel File, filename with date\n",
    "filename = \"output/forecast_\" + time.strftime(\"%Y-%m-%d\") + \".xlsx\"\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "df.to_excel(filename, index=False)\n",
    "\n",
    "# Get the file size in MB\n",
    "file_size = os.path.getsize(filename) / (1024 * 1024)\n",
    "\n",
    "logging.info(f\"Excel File Created: {filename}, Size: {file_size:.2f} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 11:17:45 - INFO - BEGIN Constructing Final Data and send it back to API\n",
      "2025-01-22 11:17:45 - INFO - Start Sending 20 Row To API\n",
      "2025-01-22 11:17:45 - INFO - Send API Complete\n",
      "2025-01-22 11:17:45 - INFO - Status Code: 200\n",
      "2025-01-22 11:17:45 - INFO - Response Body: {\"success\":true,\"message\":\"20 records updated.\"}\n"
     ]
    }
   ],
   "source": [
    "# Send Data Back To API\n",
    "logging.info(\"BEGIN Constructing Final Data and send it back to API\")\n",
    "\n",
    "url = \"http://localhost:8080/main/web/postdmdcall\"\n",
    "\n",
    "# construct result with branch, agency, partno\n",
    "result = df[['branch', 'agency', 'partno', 'FD_final', 'std_12_FD', 'mean_12_FD', 'ub_FD']]\n",
    "\n",
    "# change column name\n",
    "result.columns = ['branch', 'agency', 'partno', 'fd', 'std', 'mean', 'ub']\n",
    "\n",
    "# result = df.drop('d', axis=1)\n",
    "result_json = result.to_dict(orient='records')\n",
    "\n",
    "logging.info(\"Start Sending \" + str(len(result)) + \" Row To API\")\n",
    "\n",
    "for attempt in range(1, max_retries + 1):\n",
    "    try:\n",
    "        response = requests.post(url, json=result_json)\n",
    "        response.raise_for_status() \n",
    "        logging.info(\"Send API Complete\")\n",
    "        logging.info(f\"Status Code: {response.status_code}\")\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            logging.info(f\"Response Body: {response.text}\")\n",
    "        else:\n",
    "            logging.info(\"Send Failed\")\n",
    "\n",
    "        break\n",
    "    except requests.RequestException as e:\n",
    "        logging.info(f\"Attempt {attempt}: API request failed - {e}\")\n",
    "        if attempt < max_retries:\n",
    "            time.sleep(delay * (2 ** (attempt - 1)))  # Exponential backoff\n",
    "        else:\n",
    "            logging.info(\"Max retries reached. Exiting.\")\n",
    "            sys.exit(1)  # Stop execution after max retries\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
