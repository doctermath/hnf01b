{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PACKAGES\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from statsmodels.tsa.api import SimpleExpSmoothing, Holt, ExponentialSmoothing\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Brc  Agc   P/N      Desc  DN Price DR/\\nNDR  OH  OO  Book  Alloc\\nIn  ...  \\\n",
      "3  888  88B  8810   DUMMY 4      1.31       DR  10   0     0          0  ...   \n",
      "4  999  99P  9901   DUMMY 5     15.02       DR   4   0     0          0  ...   \n",
      "5  999  99P  9902   DUMMY 6     21.87       DR   1   0     0          0  ...   \n",
      "6  999  99Q  9903   DUMMY 7      1.92       DR  29   0     0          0  ...   \n",
      "7  999  99Q  9906   DUMMY 8     20.92       DR   4   0     0          0  ...   \n",
      "8  999  99Q  9908   DUMMY 9     26.05       DR   1   6     0          0  ...   \n",
      "9  999  99R  9909  DUMMY 10     23.19       DR   5   0     0          0  ...   \n",
      "\n",
      "   Last Sales   Last GRR  Last Return  Date  Category  Bin Loc  Status  \\\n",
      "3         NaN 2020-12-04          NaN   NaT       NaN    1E29D      SS   \n",
      "4         NaN 2024-06-04          NaN   NaT       NaN    3E01A     NaN   \n",
      "5         NaN        NaT          NaN   NaT       NaN    3E01A     NaN   \n",
      "6         NaN 2024-10-07          NaN   NaT       NaN    1E35C      SS   \n",
      "7         NaN 2019-06-11          NaN   NaT       NaN    2E35C      SS   \n",
      "8         NaN 2024-09-30          NaN   NaT       NaN    2D32B     NaN   \n",
      "9         NaN 2024-09-23          NaN   NaT       NaN    2E25B     NaN   \n",
      "\n",
      "   Tot\\nAll  Tot\\nCall  Tot\\nDmd  \n",
      "3        10          0         0  \n",
      "4         4          0         0  \n",
      "5         1          0         0  \n",
      "6        29          0         0  \n",
      "7         4          0         0  \n",
      "8         7          0         0  \n",
      "9         5          0         0  \n",
      "\n",
      "[7 rows x 49 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the API endpoint\n",
    "api_url = \"http://172.16.5.6:8080/v1/web/test12\"\n",
    "df = pd.DataFrame(data['data'])\n",
    "# Fetch data from the API\n",
    "response = requests.get(api_url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Convert the JSON response to a Python dictionary\n",
    "    data = response.json()\n",
    "    \n",
    "    # Create a pandas DataFrame from the data\n",
    "    # Assuming the API response is a list of dictionaries\n",
    "    df = pd.DataFrame(data['data'])\n",
    "    \n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code}\")\n",
    "    \n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETER\n",
    "#EWMA\n",
    "alpha_ewma = 0.4\n",
    "\n",
    "#SES & DES\n",
    "alpha_ses = 0.65  # ubah nilai alpha (semakin besar semakin berat ke data terbaru)\n",
    "beta_des = 0.45   # ubah nilai beta (semakin besar semakin cepat beradaptasi, kalo rendah bisa terjadi lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'D'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Brandon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'D'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get mean and standard deviation of 12 periods before the last one\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_12\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mmean(x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m13\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))  \u001b[38;5;66;03m# Use 12 periods before the last one\u001b[39;00m\n\u001b[0;32m      3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd_12\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mstd(x[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m13\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))    \u001b[38;5;66;03m# Use 12 periods before the last one\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Get upper bound from mean and std\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'D'"
     ]
    }
   ],
   "source": [
    "# Get mean and standard deviation of 12 periods before the last one\n",
    "data['mean_12'] = data['D'].apply(lambda x: np.mean(x[-13:-1]))  # Use 12 periods before the last one\n",
    "data['std_12'] = data['D'].apply(lambda x: np.std(x[-13:-1]))    # Use 12 periods before the last one\n",
    "\n",
    "# Get upper bound from mean and std\n",
    "data['ub'] = data['mean_12'] + 1.5 * data['std_12']\n",
    "\n",
    "# Limit the original data to upper bound (using the 12 periods before the last one)\n",
    "data['clipped_d'] = data.apply(lambda row: np.clip(row['D'][-13:-1], 0, row['ub']).tolist(), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Simple Moving Average\n",
    "def calculate_ma(list):\n",
    "    oldData = []\n",
    "    newData = []\n",
    "    for i in list:\n",
    "        # store calculated data to old list\n",
    "        oldData.append(i)\n",
    "        newData.append(np.mean(oldData))\n",
    "    return newData\n",
    "\n",
    "data['ma'] = data['clipped_d'].apply(calculate_ma)\n",
    "data['ma_result'] = data['ma'].apply(lambda x: x[-1:])\n",
    "data['ma_result'] = data['clipped_d'].apply(lambda x: np.mean(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data['wma_clipped_d'] = data.apply(lambda row: np.clip(row['d'][-16:-1], 0, row['ub']).tolist(), axis=1)\n",
    "\n",
    "def wma_forecast_with_weights(data, weights):\n",
    "    wma_values = [None] * 3\n",
    "    for i in range(3, len(data)):\n",
    "        forecast = np.sum(np.array(data[i-3:i]) * weights) / sum(weights)\n",
    "        wma_values.append(forecast)\n",
    "    return wma_values\n",
    "\n",
    "def generate_weights(step=0.05):\n",
    "    weights = []\n",
    "    for w1 in np.arange(0.15, 1, step):\n",
    "        for w2 in np.arange(w1 + 0.01, 1 - w1, step):\n",
    "            w3 = 1 - w1 - w2\n",
    "            if w3 > w2 > w1 > 0 and abs(w1 + w2 + w3 - 1) < 1e-6:\n",
    "                weights.append((w1, w2, w3))\n",
    "    return weights\n",
    "\n",
    "best_weights_list = []\n",
    "best_maes = []\n",
    "\n",
    "for row in data['wma_clipped_d']:\n",
    "    best_mae = float('inf')\n",
    "    best_weights = None\n",
    "    for weights in generate_weights(step=0.05):\n",
    "        wma_values = wma_forecast_with_weights(row, weights)\n",
    "        mae = mean_absolute_error(row[-12:], wma_values[-12:])\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_weights = weights\n",
    "    best_weights_list.append(best_weights)\n",
    "    best_maes.append(best_mae)\n",
    "\n",
    "data['best_weights'] = best_weights_list\n",
    "data['best_mae'] = best_maes\n",
    "\n",
    "data['wma'], data['wma_result'] = zip(*data.apply(lambda row: (\n",
    "    wma_forecast_with_weights(row['wma_clipped_d'], row['best_weights'])[3:][-12:],\n",
    "    wma_forecast_with_weights(row['wma_clipped_d'], row['best_weights'])[-1:]\n",
    "), axis=1))\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Exponential Weighted Moving Average (EWMA)\n",
    "def ewma(list, alpha = alpha_ewma):\n",
    "    df = pd.DataFrame(list)\n",
    "    df['ewma'] = df.ewm(alpha=alpha_ewma, adjust=False).mean()\n",
    "    return df['ewma'].tolist()\n",
    "\n",
    "def ewma_forecast(list, alpha):\n",
    "    ewma_values = ewma(list, alpha)\n",
    "    if len(ewma_values) > 0:\n",
    "        # Prediction for the next period\n",
    "        next_forecast = (1 - alpha) * ewma_values[-1]\n",
    "    else:\n",
    "        next_forecast = None\n",
    "    return ewma_values, next_forecast\n",
    "\n",
    "data['ewma'], data['ewma_result'] = zip(*data['clipped_d'].apply(lambda x: ewma_forecast(x, alpha_ewma)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LINEAR REGRESSION\n",
    "#  Calculate Linear Regression\n",
    "def lr(x):\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = x\n",
    "    df['x'] = range(1, len(df) + 1)\n",
    "    model =  LinearRegression()\n",
    "    model.fit(df[['x']], df['y'])\n",
    "    df.loc[len(df), 'x'] = len(df) + 1\n",
    "    return model.predict(df[['x']])\n",
    "\n",
    "data['lr'] = data['clipped_d'].apply(lambda x: lr(x))\n",
    "data['lr_result'] = data['lr'].apply(lambda x: x[-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLYNOMIAL 2ND AND 3RD\n",
    "# Calculate Polynomial Regression\n",
    "def pr(x, pr_degree):\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = x\n",
    "    df['x'] = range(1, len(df) + 1)\n",
    "\n",
    "    X = df[['x']]  # Independent variable (reshape to 2D array)\n",
    "    y = df['y']    # Dependent variable\n",
    "\n",
    "    poly = PolynomialFeatures(degree=pr_degree)  # Create polynomial features\n",
    "    X_poly = poly.fit_transform(X)  # Transform input features\n",
    "    poly_model = LinearRegression()  # Initialize linear regression model\n",
    "    poly_model.fit(X_poly, y)  # Fit polynomial model\n",
    "\n",
    "    df.loc[len(df), 'x'] = len(df) + 1\n",
    "    X_all_poly = poly.transform(df[['x']])\n",
    "    return poly_model.predict(X_all_poly)  \n",
    "\n",
    "data['pr2'] = data['clipped_d'].apply(lambda x: pr(x, 2))\n",
    "data['pr2_result'] = data['pr2'].apply(lambda x: x[-1:])\n",
    "data['pr3'] = data['clipped_d'].apply(lambda x: pr(x, 3))\n",
    "data['pr3_result'] = data['pr3'].apply(lambda x: x[-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SES\n",
    "def ses(x, alpha = alpha_ses):\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = x\n",
    "    df['x'] = range(1, len(df) + 1)\n",
    "    df.loc[len(df), 'x'] = len(df) + 1\n",
    "\n",
    "    new_data = SimpleExpSmoothing(df['y']).fit(smoothing_level=alpha, optimized=False).fittedvalues\n",
    "    return new_data.tolist()\n",
    "\n",
    "data['ses'] = data['clipped_d'].apply(lambda x: ses(x, alpha_ses))\n",
    "data['ses_result'] = data['ses'].apply(lambda x: x[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DES\n",
    "def des(x, alpha = alpha_ses, beta = beta_des):\n",
    "    df = pd.DataFrame()\n",
    "    df['y'] = x\n",
    "    df['x'] = range(1, len(df) + 1)\n",
    "    df.loc[len(df), 'x'] = len(df) + 1\n",
    "\n",
    "    new_data = ExponentialSmoothing(df['y'], trend='add', seasonal=None).fit(smoothing_level=alpha, smoothing_trend=beta, optimized=False).fittedvalues\n",
    "    return new_data.tolist()\n",
    "\n",
    "data['des'] = data['clipped_d'].apply(lambda x: des(x,alpha_ses, beta_des))\n",
    "data['des_result'] = data['des'].apply(lambda x: x[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(x):\n",
    "    period_length = len(x['clipped_d'])\n",
    "    df = pd.DataFrame()\n",
    "    df['period'] = range(1, period_length + 1)\n",
    "    df['qty'] = x['clipped_d'][:period_length]  # Ground truth values\n",
    "    df['ma'] = x['ma'][:period_length]\n",
    "    df['wma'] = x['wma'][:period_length]\n",
    "    df['ewma'] = x['ewma'][:period_length]\n",
    "    df['lr'] = x['lr'][:period_length]\n",
    "    df['pr2'] = x['pr2'][:period_length]\n",
    "    df['pr3'] = x['pr3'][:period_length]\n",
    "    df['ses'] = x['ses'][:period_length]\n",
    "    df['des'] = x['des'][:period_length]\n",
    "\n",
    "    # Calculate metrics for each model\n",
    "    result = []\n",
    "    for model in df.columns[2:]:  # Loop through model columns (ma, ewma, etc.)\n",
    "        rmse = np.sqrt(mean_squared_error(df['qty'], df[model]))  # Calculate RMSE\n",
    "        r2 = r2_score(df['qty'], df[model])  # Calculate R²\n",
    "        mae = mean_absolute_error(df['qty'], df[model])  # Calculate MAE\n",
    "        result.append({'model': model, 'RMSE': rmse, 'MAE': mae, 'R2': r2})\n",
    "    \n",
    "    # Convert result to a DataFrame\n",
    "    metrics_df = pd.DataFrame(result)\n",
    "    \n",
    "    # Select the best model (e.g., based on RMSE)\n",
    "    best_model_row = metrics_df.loc[metrics_df['MAE'].idxmin()]  # Row with the lowest RMSE\n",
    "    best_model = best_model_row['model']\n",
    "    \n",
    "    # Add the best model and metrics to the result\n",
    "    return {'best_model': best_model, 'metrics': metrics_df.to_dict(orient='records')}\n",
    "\n",
    "# Apply the metric function\n",
    "data['metric'] = data.apply(lambda x: metric(x), axis=1)\n",
    "\n",
    "# Extract the best model and metrics for each row\n",
    "data['best_model'] = data['metric'].apply(lambda x: x['best_model'])\n",
    "data['metrics'] = data['metric'].apply(lambda x: x['metrics'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['mean_12_FD'] = data['d'].apply(lambda x: np.mean(x[-12:]))\n",
    "data['std_12_FD'] = data['d'].apply(lambda x: np.std(x[-12:]))\n",
    "\n",
    "data['ub_FD'] = data['mean_12_FD'] + 1.5 * data['std_12_FD']\n",
    "\n",
    "data['clipped_d_FD'] = data.apply(lambda row: np.clip(row['d'][-12:], 0, row['ub_FD']).tolist(), axis=1)\n",
    "def apply_best_model_forecast(row):\n",
    "    best_model = row['best_model']\n",
    "    \n",
    "    data = row['D'][-15:] if best_model == 'wma' else row['d'][-12:]\n",
    "    \n",
    "    ub = row['ub_FD']\n",
    "    clipped_data = np.clip(data, 0, ub).tolist()\n",
    "    \n",
    "    if best_model == 'ma':\n",
    "        ma_values = calculate_ma(clipped_data)\n",
    "        forecast = ma_values[-1]\n",
    "    elif best_model == 'ewma':\n",
    "        alpha = 0.4\n",
    "        weights = np.array([(1 - alpha) ** i for i in range(len(clipped_data))][::-1])\n",
    "        forecast = np.sum(weights * clipped_data) / np.sum(weights)\n",
    "    elif best_model == 'wma':\n",
    "        weights = [0.2, 0.3, 0.5]\n",
    "        if len(clipped_data) >= len(weights):\n",
    "            forecast = np.sum(np.array(clipped_data[-3:]) * weights)\n",
    "        else:\n",
    "            forecast = np.nan\n",
    "    elif best_model == 'lr':\n",
    "        X = np.arange(len(clipped_data)).reshape(-1, 1)\n",
    "        y = np.array(clipped_data)\n",
    "        coef = np.polyfit(X.flatten(), y, 1)\n",
    "        forecast = coef[0] * len(clipped_data) + coef[1]\n",
    "    elif best_model == 'pr2':\n",
    "        X = np.arange(len(clipped_data)).reshape(-1, 1)\n",
    "        y = np.array(clipped_data)\n",
    "        coef = np.polyfit(X.flatten(), y, 2)\n",
    "        forecast = coef[0] * (len(clipped_data) ** 2) + coef[1] * len(clipped_data) + coef[2]\n",
    "    elif best_model == 'pr3':\n",
    "        X = np.arange(len(clipped_data)).reshape(-1, 1)\n",
    "        y = np.array(clipped_data)\n",
    "        coef = np.polyfit(X.flatten(), y, 3)\n",
    "        forecast = (\n",
    "            coef[0] * (len(clipped_data) ** 3)\n",
    "            + coef[1] * (len(clipped_data) ** 2)\n",
    "            + coef[2] * len(clipped_data)\n",
    "            + coef[3]\n",
    "        )\n",
    "    elif best_model == 'ses':\n",
    "        model = SimpleExpSmoothing(clipped_data).fit(smoothing_level=0.65, optimized=False)\n",
    "        forecast = model.forecast(1)[0]\n",
    "    elif best_model == 'des':\n",
    "        model = Holt(clipped_data).fit(smoothing_level=0.65, smoothing_slope=0.45, optimized=False)\n",
    "        forecast = model.forecast(1)[0]\n",
    "    else:\n",
    "        forecast = np.nan\n",
    "    \n",
    "    return forecast\n",
    "\n",
    "data['FD_forecast'] = data.apply(apply_best_model_forecast, axis=1)\n",
    "\n",
    "data['FD_final'] = data['FD_forecast'].apply(np.ceil)\n",
    "data['FD_final'] = data['FD_final'].apply(lambda x: max(0, np.ceil(x)))\n",
    "\n",
    "display(data[['partno','best_model', 'FD_forecast', 'FD_final']])\n",
    "display(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
